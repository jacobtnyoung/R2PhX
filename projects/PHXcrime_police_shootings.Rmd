---
title: "Police Shootings in Phoenix?"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: yeti
    toc: false
    toc_float: false
    collapsed: false
    smooth_scroll: false
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.width = 12, 
                      fig.height = 10)

rm(list = ls())

```

<br>

[Officer Involved Shooting Incidents](https://www.phoenixopendata.com/dataset/officer-involved-shooting-incidents) 

### Header {.tabset}

INFO FROM THE WEBSITE:

A CSV file that includes Phoenix Police Department officer involved shooting incidents from January 1, 2017 forward. The available CSV file is refreshed each hour but updates following new OIS incidents are only completed after information is compiled for all the fields displayed in the dataset, which may take a few days following each new OIS incident. More than one officer may discharge their weapon during the same incident. Accidental discharges, discharges at animals, and discharges at objects where there was not an active threat by a subject are not included in this data set.

<br>

```{r, echo = FALSE, eval = TRUE}
url <- "https://www.phoenixopendata.com/dataset/1e472b1f-80c1-4686-b80f-e930616f8580/resource/8f8c1739-b905-407f-9eb6-6b10db55b931/download/ois.csv"
shooting.data <- read.csv( url, as.is = TRUE, header = TRUE )
shooting.data <- na.omit( shooting.data )
```

#### Getting and Pre-processing the Data  

Let's pull the most recent data for **officer involved shooting incidents** from the site.

```{r, echo = FALSE, eval = TRUE}
library(scales)
n.cases <- dim( crime.data )[1]
```  

The data are reported as UCR crime classifications and have geographic information (block address, zip) as well as the date and time of the incident. As of `r format(Sys.time(), '%B, %Y')`, there were `r comma(n.cases)` crime incidents with complete data from 11/2015 to within a week of the current date.   

#### Getting the data (code)  
```{r, echo = TRUE, eval = FALSE}

# set the url where the data are located.
url <- "https://www.phoenixopendata.com/dataset/1e472b1f-80c1-4686-b80f-e930616f8580/resource/8f8c1739-b905-407f-9eb6-6b10db55b931/download/ois.csv"

# pull in the csv file.
shooting.data <- read.csv( url, as.is = TRUE, header = TRUE )

# drop cases missing on date.
shooting.data <- na.omit( shooting.data )

# take a look at the data.
head( shooting.data )  

``` 

!!!HERE WITH WORKING THROUGH IT


#### Preprocessing the data (code)  

Now that the data are in the workspace, let's clean up the date and the crime categories to make plotting them fairly easy. To do so, I am drawing from a [lab](https://ds4ps.org/cpp-526-sum-2020/labs/lab-05-instructions.html) from ASU's [Foundations of Data Science Part I](https://ds4ps.org/) course in the Program Evaluation and Data Analytics. See the "Working with Dates" section of the site. We will use the `strptime()` and `format()` functions here.

```{r, echo = TRUE, eval = TRUE}

# The date and time variable is a character string.
head( crime.data$OCCURRED.ON )
is.character( crime.data$OCCURRED.ON )

# Convert the string dates to a date format code.
date.vec <- strptime( crime.data$OCCURRED.ON, format="%m/%d/%Y %H:%M" )
head( date.vec )
tail( date.vec )

# Now, let's use the format() function to create several objects based on the date and time.
crime.data$year   <- format( date.vec, format="%Y" )
crime.data$month  <- format( date.vec, format="%B" )
crime.data$day365 <- format( date.vec, format="%j" )
crime.data$week   <- format( date.vec, format="%V" )

```

Let's start by looking at the daily counts of crime from when the data are first available (i.e. November 2015) and look at the trend up to the current date. 

```{r, echo = TRUE, eval = TRUE}

# Now, let's use dplyr and tidyr to get the data in a format where we can look at the time series.
library( dplyr )
library( tidyr )


# Use dplyr() to create an object that is the daily count of crimes.
crimes.by.day <- 
  crime.data %>% 
  select( year, month, day365 ) %>%   
  filter( !is.na( day365 ) ) %>% 
  group_by( year, month, day365 ) %>% 
  summarize( counts = n() ) %>% 
  ungroup() %>% 
  mutate( day.time = seq( 1, length( counts ) ) ) %>% 
  select( counts, day.time ) %>% 
  mutate( days = seq( as.Date( "2015/11/1" ), as.Date( tail( date.vec ) )[1], "days" ) ) %>% 
  arrange( day.time )

# Finally, let's take a look using ggplot2.
library( ggplot2 )

# Add the dates for the plot.
crimes.by.day <- as.data.frame( crimes.by.day )

# Now let's plot it!
crimes.by.day %>% 
  ggplot( aes( days, counts ) ) +
  geom_line( color = "grey80" ) +
  geom_point( alpha = 1/5, color = "black" ) +
  labs( x = "", y = "Counts of Crime per Day" ) + 
  ggtitle( "Daily Crime Counts in Phoenix from Nov. 2015 to Sept. 2020" ) +
  geom_smooth( color = "darkblue", span = 0.2 ) +
  scale_y_continuous(label = comma) +
  theme_minimal() 

```

The plot shows a fairly stable daily count of crimes. *But*, a marked **decline** beginning at the end of 2019.  

The daily count view is useful, but it might help if we break it down by year and month. That is because there is a seasonality to crime incidents. One way to show this is to plot the monthly incident count for each year.  

This takes some reworking of the data. Rather than collapsing by day, we want to record counts by month. *However*, the major change is that we need to create a `ts()` object. That is, we need to create a time series object using the `ts()` function. We will also use the `ggseasonplot()` from the `forecast` package.


```{r, echo = TRUE, eval = TRUE}

# Back to dplyr! Let's create an object that is monthly counts and sorted by year. 
crimes.by.month <- 
  crime.data %>% 
  select( year, month ) %>%   
  filter( year != 2015 ) %>%  
  filter( !is.na( year ) ) %>% 
  group_by( year, month ) %>% 
  summarize( counts = n() ) %>% 
  spread( year, counts ) %>% 
  arrange( match( month, month.name ) ) %>% 
  select( !month )

# Now, lets use the ts() function to create a time series object.
monthly.crimes.by.year <- ts(
  matrix( as.matrix( crimes.by.month ), ncol = 1 ), start=c( 2016, 1 ), end=c( 2020, 12 ), frequency=12
  )

# Finally, let's take a look using ggseasonplot().
library( ggplot2 )
library( forecast )

monthly.crimes.by.year %>% 
  ggseasonplot(
   year.labels=FALSE,
   main = "Plot of Monthly Crime Count by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

```

<br><br>

Note that for 2020, the line stops in September, that is the last month we have data from the portal.  


### What about adjusting for population changes?

If you just said, **BUT** these are counts and do not reflect population differences! Your right! So, let's pull population data from the [Census Bureau](https://www.census.gov/topics/population.html). Specifically, the data for [Arizona](https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES-04.xlsx). This is an Excel file with estimates of population for incorporated places. Since this is an .xlxs file, we will use the `openxlxs` package.

Let's pull it in and get the data for Phoenix.

```{r, echo = FALSE, eval = TRUE}
library(openxlsx)

# get the data.
pop.data <- read.xlsx(
  "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES-04.xlsx",
  colNames = TRUE,
  startRow = 4
  )

# Find the row with the data for Phoenix.
grep("Phoenix", pop.data[,1])

# It is the 55th row in the object. So, we need to pull that row.
phoenix.pop <-  pop.data[55,]
phoenix.pop

# Now, we only need the data for 2016-2019.
phoenix.pop <- phoenix.pop[-c(1:9)]
phoenix.pop

```

Ok! We have our population data. But, what about 2020? It is not reported yet. So, we need to fill that in. We could do this various ways, but for ease, let's just add the difference in growth from 2018 to 2019. 

```{r, echo = FALSE, eval = TRUE}

# now, lets create a vector for population and add it to your object.
phoenix.pop.data <- as.numeric( c( phoenix.pop,( phoenix.pop[4] + phoenix.pop[4] - phoenix.pop[3] ) ) )

# now, calculate the crime rate. Crime rate is calculated as the count of crimes divided by the population size, then multipled by 100,000.

crime.rates <- as.data.frame( crimes.by.month )

for (i in 1:5){
 crime.rates[,i] <- ( crime.rates[,i] / phoenix.pop.data[i] ) * 100000
}

# Create the time series.
monthly.crime.rate.by.year <- ts(
  matrix( as.matrix( crime.rates ), ncol = 1 ), start=c( 2016, 1 ), end=c( 2020, 12 ), frequency=12
  )

monthly.crime.rate.by.year %>% 
  ggseasonplot(
   year.labels=FALSE,
   main = "Plot of Monthly Crime Rate by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

```

Well, how does the population change matter? Let's take a look at the counts and the rates together. Note that to get these together, we need to use the `grid.arrange()` function in the `gridExtra` package.

```{r, echo = FALSE, eval = TRUE}
library(gridExtra)

p1 <- monthly.crimes.by.year %>% 
  ggseasonplot(
   year.labels=FALSE,
   main = "Plot of Monthly Crime Count by Years for Phoenix" ) + 
   scale_y_continuous(label = comma) +
  theme_gray() 

p2 <- monthly.crime.rate.by.year %>% 
  ggseasonplot(
   year.labels=FALSE,
   main = "Plot of Monthly Crime Rate by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

grid.arrange(p1, p2, ncol = 1)

```

There is little change in the plot when we adjust for population differences by year.
