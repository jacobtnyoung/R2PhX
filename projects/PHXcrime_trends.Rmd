---
title: "What is going on with crime in Phoenix?"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: yeti
    toc: false
    toc_float: false
    collapsed: false
    smooth_scroll: false
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.width = 12, 
                      fig.height = 10)

rm(list = ls())

```


```{r, echo = FALSE, eval = TRUE}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# I run this chunk so that I can go through it and have the tabs show the code.

library( dplyr )
library( tidyr )
library( ggplot2 )

# Get the data.
url <- "https://www.phoenixopendata.com/dataset/cc08aace-9ca9-467f-b6c1-f0879ab1a358/resource/0ce3411a-2fc6-4302-a33f-167f68608a20/download/crimestat.csv"
crime.data <- read.csv( url, as.is = TRUE, header = TRUE )
crime.data <- na.omit( crime.data )

# Help with formating the text.
library(scales)
n.cases <- dim( crime.data )[1]

# Clean up the dates.
date.vec <- strptime( crime.data$OCCURRED.ON, format="%m/%d/%Y %H:%M" )
crime.data$year   <- format( date.vec, format="%Y" )
crime.data$month  <- format( date.vec, format="%B" )
crime.data$day365 <- format( date.vec, format="%j" )
crime.data$week   <- format( date.vec, format="%V" )

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# Use dplyr() to create an object that is the daily count of crimes.
crimes.by.day <- 
  crime.data %>% 
  select( year, month, day365 ) %>%   
  filter( !is.na( day365 ) ) %>% 
  group_by( year, month, day365 ) %>% 
  summarize( counts = n() ) %>% 
  ungroup() %>% 
  mutate( day.time = seq( 1, length( counts ) ) ) %>% 
  select( counts, day.time ) %>% 
  mutate( days = seq( as.Date( "2015/11/1" ), as.Date( tail( date.vec ) )[1], "days" ) ) %>% 
  arrange( day.time )

crimes.by.day <- as.data.frame( crimes.by.day )

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# Back to dplyr! Let's create an object that is monthly counts and sorted by year. 
crimes.by.month <- 
  crime.data %>% 
  select( year, month ) %>%   
  filter( year != 2015 ) %>%  
  filter( !is.na( year ) ) %>% 
  group_by( year, month ) %>% 
  summarize( counts = n() ) %>% 
  spread( year, counts ) %>% 
  arrange( match( month, month.name ) ) %>% 
  select( !month )

# Now, lets use the ts() function to create a time series object.
monthly.crimes.by.year <- ts(
  matrix( as.matrix( crimes.by.month ), ncol = 1 ), 
  start=c( 2016, 1 ), 
  end=c( as.numeric( tail( names( crimes.by.month ), n=1 ) ), 12 ), frequency=12
)

# Finally, let's take a look using ggseasonplot().
library( ggplot2 )
library( forecast )

```


<br>

What do you think? Is crime on the rise? Is crime declining? Having a hard time answering that question (**and** *being confident about your answer*)? Well, you should! I certainly do (and [I am a criminologist](https://jacobtnyoung.github.io/)).  

<br>

But, so are most people. [Gallup polling](https://news.gallup.com/poll/268283/describe-problem-crime-serious.aspx) has consistently shown that individuals' perceptions of crime does not (REPEAT **does not**) track trends in crime.  

As I discuss in a [different post](https://jacobtnyoung.github.io/R2PhX/projects/PHXcrime.html), crime trends are **very** difficult to assess, without seeing the data, because of the peculiar nature of crime and the huge delay in reporting of crime (because of the way it is collected). 

If we want to know what is going on with crime in Phoenix, we can take a look at the [Crime Incidents](https://www.phoenixopendata.com/dataset/crime-data) data from the [data portal](https://www.phoenixopendata.com/). The city updates the file at 11am every day and it contains data beginning November 2015 up to 7 days before the posting date.

<br><br>


### To the data! {.tabset}

<br>

#### Daily trend

<br>

Let's pull the most recent data for **crime incidents** from the site.

The data are reported as UCR crime classifications and have geographic information (block address, zip) as well as the date and time of the incident. As of `r format(Sys.time(), '%B, %Y')`, there were `r comma(n.cases)` crime incidents with complete data from 11/2015 to within a week of the current date.   

Let's start by looking at the daily counts of crime from when the data are first available (i.e. November 2015) and look at the trend up to the current date. 

<br>

```{r, echo = FALSE, eval = TRUE}

crimes.by.day %>% 
  ggplot( aes( days, counts ) ) +
  geom_line( color = "grey80" ) +
  geom_point( alpha = 1/5, color = "black" ) +
  labs( x = "", y = "Counts of Crime per Day" ) + 
  ggtitle( "Daily Crime Counts in Phoenix, AZ" ) +
  geom_smooth( color = "darkblue", span = 0.2 ) +
  scale_y_continuous(label = comma) +
  theme_minimal() 

```

<br>
The plot shows a fairly stable daily count of crimes. *But*, a marked **decline** beginning at the end of 2019. Based in this analysis, it would appear that since the end of 2019, crime incidents have been trending down in Phoenix.  
<br>

There does appear to be a slight uptick for `r format(Sys.time(), '%Y')`. For a more in-depth glance at `r format(Sys.time(), '%Y')`, check out [this post](https://jacobtnyoung.github.io/R2PhX/projects/PHXcrime_types.html).
<br>

<br><br>

#### Getting the data (**code**)  

<br>

```{r, echo = TRUE, eval = FALSE}

# set the url where the data are located.
url <- "https://www.phoenixopendata.com/dataset/cc08aace-9ca9-467f-b6c1-f0879ab1a358/resource/0ce3411a-2fc6-4302-a33f-167f68608a20/download/crimestat.csv"

# pull in the csv file.
crime.data <- read.csv( url, as.is = TRUE, header = TRUE )

# drop cases missing on date.
crime.data <- na.omit( crime.data )

# take a look at the data.
head( crime.data )  

``` 

#### Preprocessing the data (**code**)  

<br>

Now that the data are in the workspace, let's clean up the date and the crime categories to make plotting them fairly easy. To do so, I am drawing from a [lab](https://ds4ps.org/cpp-526-sum-2020/labs/lab-05-instructions.html) from ASU's [Foundations of Data Science Part I](https://ds4ps.org/) course in the Program Evaluation and Data Analytics. See the "Working with Dates" section of the site. We will use the `strptime()` and `format()` functions here.

<br>

```{r, echo = TRUE, eval = TRUE}

# The date and time variable is a character string.
head( crime.data$OCCURRED.ON )
is.character( crime.data$OCCURRED.ON )

# Convert the string dates to a date format code.
date.vec <- strptime( crime.data$OCCURRED.ON, format="%m/%d/%Y %H:%M" )
head( date.vec )
tail( date.vec )

# Now, let's use the format() function to create several objects based on the date and time.
crime.data$year   <- format( date.vec, format="%Y" )
crime.data$month  <- format( date.vec, format="%B" )
crime.data$day365 <- format( date.vec, format="%j" )
crime.data$week   <- format( date.vec, format="%V" )

```

#### Plotting the data (**code**)

<br>

```{r, echo = TRUE, eval = FALSE}

# Now, let's use dplyr and tidyr to get the data in a format where we can look at the time series.
library( dplyr )
library( tidyr )

# Use dplyr() to create an object that is the daily count of crimes.
crimes.by.day <- 
  crime.data %>% 
  select( year, month, day365 ) %>%   
  filter( !is.na( day365 ) ) %>% 
  group_by( year, month, day365 ) %>% 
  summarize( counts = n() ) %>% 
  ungroup() %>% 
  mutate( day.time = seq( 1, length( counts ) ) ) %>% 
  select( counts, day.time ) %>% 
  mutate( days = seq( as.Date( "2015/11/1" ), as.Date( tail( date.vec ) )[1], "days" ) ) %>% 
  arrange( day.time )

# Finally, let's take a look using ggplot2.
library( ggplot2 )

# Add the dates for the plot.
crimes.by.day <- as.data.frame( crimes.by.day )

# Now let's plot it!
crimes.by.day %>% 
  ggplot( aes( days, counts ) ) +
  geom_line( color = "grey80" ) +
  geom_point( alpha = 1/5, color = "black" ) +
  labs( x = "", y = "Counts of Crime per Day" ) + 
  ggtitle( "Daily Crime Counts in Phoenix from Nov. 2015 to Sept. 2020" ) +
  geom_smooth( color = "darkblue", span = 0.2 ) +
  scale_y_continuous(label = comma) +
  theme_minimal() 

```


### What about crime by year and month? {.tabset}

<br>

#### Seasonality

<br>

The daily count view is useful, but it might help if we break it down by year and month. That is because there is a seasonality to crime incidents. One way to show this is to plot the monthly incident count for each year. Note that for `r format(Sys.time(), '%Y')`, the line stops in `r format(Sys.time(), '%B')`, that is the last month we have data from the portal (or, since I last updated this page :flushed: ).  
  
<br>

```{r, echo=FALSE, eval=TRUE}

monthly.crimes.by.year %>% 
  ggseasonplot(
    year.labels=FALSE,
    main = "Plot of Monthly Crime Count by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

```

<br>

This plot reinforces what we observed in the plot above. Mainly, that the trend for 2020 is *unusual* relative to other years. 

<br>

#### Reworking the data (**code**) 

<br>

This takes some reworking of the data. Rather than collapsing by day, we want to record counts by month. *However*, the major change is that we need to create a `ts()` object. That is, we need to create a time series object using the `ts()` function. We will also use the `ggseasonplot()` from the `forecast` package.

<br>

```{r, echo = TRUE, eval = FALSE}

# Back to dplyr! Let's create an object that is monthly counts and sorted by year. 
crimes.by.month <- 
  crime.data %>% 
  select( year, month ) %>%   
  filter( year != 2015 ) %>%  
  filter( !is.na( year ) ) %>% 
  group_by( year, month ) %>% 
  summarize( counts = n() ) %>% 
  spread( year, counts ) %>% 
  arrange( match( month, month.name ) ) %>% 
  select( !month )

# Now, lets use the ts() function to create a time series object.
monthly.crimes.by.year <- ts(
  matrix( as.matrix( crimes.by.month ), ncol = 1 ), start=c( 2016, 1 ), end=c( 2020, 12 ), frequency=12
)

```

#### Plotting the data (**code**)

<br>

```{r, echo = TRUE, eval = FALSE}

# Let's take a look using ggseasonplot().
library( ggplot2 )
library( forecast )

monthly.crimes.by.year %>% 
  ggseasonplot(
    year.labels=FALSE,
    main = "Plot of Monthly Crime Count by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

```


#### Adjusting for population (**code**)

If you just said, **BUT** these are counts and do not reflect population differences! Your right! So, let's pull population data from the [Census Bureau](https://www.census.gov/topics/population.html). Specifically, the data for [Arizona](https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES-04.xlsx). This is an Excel file with estimates of population for incorporated places. Since this is an .xlxs file, we will use the `openxlxs` package.

Let's pull it in and get the data for Phoenix.

```{r, echo = TRUE, eval = TRUE}
library(openxlsx)

# get the data.
pop.data <- read.xlsx(
  "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES-04.xlsx",
  colNames = TRUE,
  startRow = 4
)

# Find the row with the data for Phoenix.
grep("Phoenix", pop.data[,1])

# It is the 55th row in the object. So, we need to pull that row.
phoenix.pop <-  pop.data[55,]
phoenix.pop

# Now, we only need the data for 2016-2019.
phoenix.pop <- phoenix.pop[-c(1:9)]
phoenix.pop

```

Ok! We have our population data. But, what about 2020? It is not reported yet. So, we need to fill that in. We could do this various ways, but for ease, let's just add the difference in growth from 2018 to 2019. 

```{r, echo = TRUE, eval = TRUE}

# now, lets create a vector for population and add it to your object.
phoenix.pop.data <- as.numeric( c( phoenix.pop,( phoenix.pop[4] + phoenix.pop[4] - phoenix.pop[3] ) ) )

# now, calculate the crime rate. Crime rate is calculated as the count of crimes divided by the population size, then multipled by 100,000.

crime.rates <- as.data.frame( crimes.by.month )

for (i in 1:5){
 crime.rates[,i] <- ( crime.rates[,i] / phoenix.pop.data[i] ) * 100000
}

# Create the time series.
monthly.crime.rate.by.year <- ts(
  matrix( as.matrix( crime.rates ), ncol = 1 ), start=c( 2016, 1 ), end=c( 2020, 12 ), frequency=12
  )

monthly.crime.rate.by.year %>% 
  ggseasonplot(
   year.labels=FALSE,
   main = "Plot of Monthly Crime Rate by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

```

Well, how does the population change matter? Let's take a look at the counts and the rates together. Note that to get these together, we need to use the `grid.arrange()` function in the `gridExtra` package.

```{r, echo = TRUE, eval = TRUE}
library(gridExtra)

p1 <- monthly.crimes.by.year %>% 
  ggseasonplot(
    year.labels=FALSE,
    main = "Plot of Monthly Crime Count by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

p2 <- monthly.crime.rate.by.year %>% 
  ggseasonplot(
    year.labels=FALSE,
    main = "Plot of Monthly Crime Rate by Years for Phoenix" ) + 
  scale_y_continuous(label = comma) +
  theme_gray() 

grid.arrange(p1, p2, ncol = 1)

```

There is little change in the plot when we adjust for population differences by year.


###

<br>

<p align="center">
[Back to R 2 Phoenix page](https://jacobtnyoung.github.io/R2PhX/)
</p>

<br>

###### ***Last updated `r format(Sys.time(), '%d %B, %Y')`***